diff --git a/README.md b/README.md
index 49b6a69..0ddaaaf 100644
--- a/README.md
+++ b/README.md
@@ -1,5 +1,5 @@
 # Ceph - a scalable distributed storage system
-
+ 
 Please see http://ceph.com/ for current info.
 
 
diff --git a/src/ceph_osd.cc b/src/ceph_osd.cc
index 998f370..0d304f9 100644
--- a/src/ceph_osd.cc
+++ b/src/ceph_osd.cc
@@ -20,6 +20,8 @@
 #include <iostream>
 #include <string>
 
+#include <hi_coreutil.h>
+
 #include "osd/OSD.h"
 #include "os/ObjectStore.h"
 #include "mon/MonClient.h"
@@ -714,6 +716,7 @@ flushjournal_out:
   if (err < 0) {
     derr << TEXT_RED << " ** ERROR: osd init failed: " << cpp_strerror(-err)
          << TEXT_NORMAL << dendl;
+    HiFinish();
     forker.exit(1);
   }
 
@@ -746,6 +749,7 @@ flushjournal_out:
   unregister_async_signal_handler(SIGTERM, handle_osd_signal);
   shutdown_async_signal_handler();
 
+  HiFinish();
   // done
   delete osd;
   delete ms_public;
diff --git a/src/common/buffer.cc b/src/common/buffer.cc
index 7ff9439..e39bf5a 100644
--- a/src/common/buffer.cc
+++ b/src/common/buffer.cc
@@ -1316,13 +1316,12 @@ static ceph::spinlock debug_lock;
   void buffer::list::reserve(size_t prealloc)
   {
     if (get_append_buffer_unused_tail_length() < prealloc) {
-      auto ptr = ptr_node::create(buffer::create_page_aligned(prealloc));
+      auto ptr = ptr_node::create(buffer::create_small_page_aligned(prealloc));
       ptr->set_length(0);   // unused, so far.
       _carriage = ptr.get();
       _buffers.push_back(*ptr.release());
     }
   }
-
   // sort-of-like-assignment-op
   void buffer::list::claim(list& bl, unsigned int flags)
   {
diff --git a/src/common/legacy_config_opts.h b/src/common/legacy_config_opts.h
index a5dace9..a847343 100644
--- a/src/common/legacy_config_opts.h
+++ b/src/common/legacy_config_opts.h
@@ -663,6 +663,11 @@ OPTION(osd_ignore_stale_divergent_priors, OPT_BOOL) // do not assert on divergen
 // If set to true even after reading enough shards to
 // decode the object, any error will be reported.
 OPTION(osd_read_ec_check_for_errors, OPT_BOOL) // return error if any ec shard has an error
+OPTION(osd_ec_partial_read,OPT_BOOL) //enable ec partial read
+OPTION(osd_ec_partial_write,OPT_BOOL) //enable ec partial write
+OPTION(kpsec_log_fullpath,OPT_STR) //The path to store KPS_EC log
+OPTION(kpsec_log_level,OPT_STR) //The level of kpsec_log
+OPTION(kpsec_log_memlogsize,OPT_U64) //kpsec_memlog_size
 
 // Only use clone_overlap for recovery if there are fewer than
 // osd_recover_clone_overlap_limit entries in the overlap set
diff --git a/src/common/options.cc b/src/common/options.cc
index e490cb3..af70114 100644
--- a/src/common/options.cc
+++ b/src/common/options.cc
@@ -3305,6 +3305,28 @@ std::vector<Option> get_global_options() {
     .set_default(false)
     .set_description(""),
 
+    Option("osd_ec_partial_read", Option::TYPE_BOOL, Option::LEVEL_ADVANCED)
+    .set_default(true)
+    .set_description("Try to read necessary chunks instead of all chunks in a stripe in ECBackend."
+		     "This option helps to reduce IO and network operation and improve read performance"),
+
+    Option("osd_ec_partial_write", Option::TYPE_BOOL, Option::LEVEL_ADVANCED)
+    .set_default(true)
+    .set_description("Try to read and write partial chunks instead of a complete stripe in erasure code data pool."
+		     "This option helps to reduce IO and network operation and improve write performance"),
+    
+    Option("kpsec_log_fullpath", Option::TYPE_STR, Option::LEVEL_ADVANCED)
+    .set_default("/var/log/ceph/")
+    .set_description("The path to store KPS_EC log, the default is /var/log/ceph/"),
+
+    Option("kpsec_log_level", Option::TYPE_STR, Option::LEVEL_ADVANCED)
+    .set_default("critical/debug")
+    .set_description("The level of kpsec_log, the default is critical/debug"),
+
+    Option("kpsec_log_memlogsize", Option::TYPE_UINT, Option::LEVEL_ADVANCED)
+    .set_default(100)
+    .set_description("Kpsec_memlog_size, it is the size of memlog_ringbuffer, the default is 100"),
+
     Option("osd_recover_clone_overlap_limit", Option::TYPE_INT, Option::LEVEL_ADVANCED)
     .set_default(10)
     .set_description(""),
diff --git a/src/osd/CMakeLists.txt b/src/osd/CMakeLists.txt
index a1b16b5..d80c5ae 100644
--- a/src/osd/CMakeLists.txt
+++ b/src/osd/CMakeLists.txt
@@ -48,7 +48,7 @@ target_link_libraries(osd
   PUBLIC dmclock::dmclock
   PRIVATE
   ${LEVELDB_LIBRARIES}
-  heap_profiler cpu_profiler ${CMAKE_DL_LIBS})
+  heap_profiler cpu_profiler ${CMAKE_DL_LIBS} kps_ec)
 if(WITH_LTTNG)
   add_dependencies(osd osd-tp pg-tp)
 endif()
diff --git a/src/osd/ECBackend.cc b/src/osd/ECBackend.cc
index 36a77cc..8e7a4b4 100644
--- a/src/osd/ECBackend.cc
+++ b/src/osd/ECBackend.cc
@@ -155,6 +155,7 @@ ostream &operator<<(ostream &lhs, const ECBackend::Op &rhs)
       << " pending_commit=" << rhs.pending_commit
       << " plan.to_read=" << rhs.plan.to_read
       << " plan.will_write=" << rhs.plan.will_write
+      << " plan.to_read_chunk_align=" << rhs.plan.to_read_chunk_align
       << ")";
   return lhs;
 }
@@ -188,6 +189,12 @@ void ECBackend::RecoveryOp::dump(Formatter *f) const
   f->dump_stream("extent_requested") << extent_requested;
 }
 
+static void log_on_exit(void *p)
+{
+}
+
+static OnExitManager exit_callbacks;
+
 ECBackend::ECBackend(
   PGBackend::Listener *pg,
   const coll_t &coll,
@@ -201,6 +208,8 @@ ECBackend::ECBackend(
     sinfo(ec_impl->get_data_chunk_count(), stripe_width) {
   ceph_assert((ec_impl->get_data_chunk_count() *
 	  ec_impl->get_chunk_size(stripe_width)) == stripe_width);
+
+  exit_callbacks.add_callback(log_on_exit, nullptr);
 }
 
 PGBackend::RecoveryHandle *ECBackend::open_recovery_op()
@@ -795,12 +804,14 @@ bool ECBackend::_handle_message(
     MOSDECSubOpWrite *op = static_cast<MOSDECSubOpWrite*>(
       _op->get_nonconst_req());
     parent->maybe_preempt_replica_scrub(op->op.soid);
+    dout(20) << __func__ << ": handle message MSG_OSD_EC_WRITE" << *_op->get_req() << dendl;
     handle_sub_write(op->op.from, _op, op->op, _op->pg_trace);
     return true;
   }
   case MSG_OSD_EC_WRITE_REPLY: {
     const MOSDECSubOpWriteReply *op = static_cast<const MOSDECSubOpWriteReply*>(
       _op->get_req());
+    dout(20) << __func__ << ": handle message MSG_OSD_EC_WRITE_REPLY" << *_op->get_req() << dendl;
     handle_sub_write_reply(op->op.from, op->op, _op->pg_trace);
     return true;
   }
@@ -1167,6 +1178,7 @@ void ECBackend::handle_sub_read_reply(
     return;
   }
   ReadOp &rop = iter->second;
+  dout(20) << __func__ << ": rop=" << rop << dendl;
   for (auto i = op.buffers_read.begin();
        i != op.buffers_read.end();
        ++i) {
@@ -1178,6 +1190,7 @@ void ECBackend::handle_sub_read_reply(
     }
     list<boost::tuple<uint64_t, uint64_t, uint32_t> >::const_iterator req_iter =
       rop.to_read.find(i->first)->second.to_read.begin();
+    bool partial_read = rop.to_read.find(i->first)->second.partial_read;
     list<
       boost::tuple<
 	uint64_t, uint64_t, map<pg_shard_t, bufferlist> > >::iterator riter =
@@ -1187,12 +1200,35 @@ void ECBackend::handle_sub_read_reply(
 	 ++j, ++req_iter, ++riter) {
       ceph_assert(req_iter != rop.to_read.find(i->first)->second.to_read.end());
       ceph_assert(riter != rop.complete[i->first].returned.end());
-      pair<uint64_t, uint64_t> adjusted =
-	sinfo.aligned_offset_len_to_chunk(
+      if(!partial_read){
+        pair<uint64_t, uint64_t> adjusted = sinfo.aligned_offset_len_to_chunk(
 	  make_pair(req_iter->get<0>(), req_iter->get<1>()));
-      ceph_assert(adjusted.first == j->first);
-      riter->get<2>()[from].claim(j->second);
+        ceph_assert(adjusted.first == j->first);
+        riter->get<2>()[from].claim(j->second);
+    }else{
+     while (req_iter != rop.to_read.find(i->first)->second.to_read.end()) {
+       //uint64_t off = sinfo.logical_to_prev_chunk_offset(req_iter->get<0>());
+       set<int> shards;
+
+       HiEcInfo ec_info(ec_impl->get_data_chunk_count(), ec_impl->get_chunk_count(),
+		        ec_impl->get_chunk_mapping(), sinfo.get_chunk_size(),
+			sinfo.get_stripe_width());
+       HiGetRelatedShards(make_pair(req_iter->get<0>(), req_iter->get<1>()), ec_info, shards);
+
+       //get_off_len_shards(req_iter->get<0>(), req_iter->get<1>(), ec_info, shards);
+        dout(20) << __func__ <<" shards:" << shards << "req" << *req_iter << "from:"
+		<< from << "j:" << *j << dendl;
+	if (shards.find(from.shard) != shards.end()) {
+	  riter->get<2>()[from].claim(j->second);
+	  break;
+	} else {
+	  req_iter++;
+	  riter++;
+	}
+	ceph_assert(req_iter != rop.to_read.find(i->first)->second.to_read.end());
+     }
     }
+   }
   }
   for (auto i = op.attrs_read.begin();
        i != op.attrs_read.end();
@@ -1241,8 +1277,9 @@ void ECBackend::handle_sub_read_reply(
         dout(20) << __func__ << " have shard=" << j->first.shard << dendl;
       }
       map<int, vector<pair<int, int>>> dummy_minimum;
-      int err;
-      if ((err = ec_impl->minimum_to_decode(rop.want_to_read[iter->first], have, &dummy_minimum)) < 0) {
+      int err = 0;
+      dout(20) << __func__ << " minimum_to_decode "<< rop.want_to_read[iter->first] << "have:" << have << dendl;
+      if (!rop.to_read.find(iter->first)->second.partial_read && (err = ec_impl->minimum_to_decode(rop.want_to_read[iter->first], have, &dummy_minimum)) < 0) {
 	dout(20) << __func__ << " minimum_to_decode failed" << dendl;
         if (rop.in_progress.empty()) {
 	  // If we don't have enough copies, try other pg_shard_ts if available.
@@ -1705,43 +1742,81 @@ void ECBackend::do_read_op(ReadOp &op)
   int priority = op.priority;
   ceph_tid_t tid = op.tid;
 
-  dout(10) << __func__ << ": starting read " << op << dendl;
+  dout(20) << __func__ << ": starting read " << op << dendl;
 
   map<pg_shard_t, ECSubRead> messages;
   for (map<hobject_t, read_request_t>::iterator i = op.to_read.begin();
        i != op.to_read.end();
        ++i) {
-    bool need_attrs = i->second.want_attrs;
-
-    for (auto j = i->second.need.begin();
-	 j != i->second.need.end();
-	 ++j) {
-      if (need_attrs) {
-	messages[j->first].attrs_to_read.insert(i->first);
-	need_attrs = false;
-      }
-      messages[j->first].subchunks[i->first] = j->second;
-      op.obj_to_source[i->first].insert(j->first);
-      op.source_to_obj[j->first].insert(i->first);
-    }
+    set<int> send_shards;
     for (list<boost::tuple<uint64_t, uint64_t, uint32_t> >::const_iterator j =
 	   i->second.to_read.begin();
 	 j != i->second.to_read.end();
 	 ++j) {
-      pair<uint64_t, uint64_t> chunk_off_len =
-	sinfo.aligned_offset_len_to_chunk(make_pair(j->get<0>(), j->get<1>()));
+           map<int,pair<uint64_t, uint64_t>> wants;
+	   pair<uint64_t, uint64_t> chunk_off_len;
+	   dout(20) << __func__ << ": second.partial_read="<< i->second.partial_read << dendl;
+	   if (i->second.partial_read) {
+	     map<int, set<pair<uint64_t, uint64_t>>> wants_tmp;
+	     HiEcInfo ec_info(ec_impl->get_data_chunk_count(), ec_impl->get_chunk_count(),
+			      ec_impl->get_chunk_mapping(), sinfo.get_chunk_size(),
+			    sinfo.get_stripe_width());
+	     HiGetShardsRangeToRead(make_pair(j->get<0>(), j->get<1>()), ec_info, wants_tmp);
+
+	     for (auto id_chunks : wants_tmp) {
+	       extent_set to_union;
+	       for (auto chunk : id_chunks.second) {
+		   to_union.union_insert(chunk.first, chunk.second);
+	       }
+	       wants.insert(make_pair(id_chunks.first,
+				      make_pair(to_union.begin().get_start(), to_union.begin().get_len())));
+	     }
+	   } else {
+            chunk_off_len =
+	      sinfo.aligned_offset_len_to_chunk(make_pair(j->get<0>(), j->get<1>()));
+	   }
+	   dout(20) << __func__ << "read_request: "<< i->second << " read off: " << j->get<0>()
+		   << "len: " << j->get<1>() << " wants: " << wants << dendl;
       for (auto k = i->second.need.begin();
 	   k != i->second.need.end();
 	   ++k) {
-	messages[k->first].to_read[i->first].push_back(
+	     if (i->second.partial_read) {
+	       if (wants.find(k->first.shard) != wants.end()) {
+		 send_shards.insert(k->first.shard);
+                 messages[k->first].to_read[i->first].push_back(
+		   boost::make_tuple(
+		     wants[k->first.shard].first,
+		     wants[k->first.shard].second,
+		     j->get<2>()));
+	       }
+	       continue;
+	     }
+        messages[k->first].to_read[i->first].push_back(
 	  boost::make_tuple(
 	    chunk_off_len.first,
 	    chunk_off_len.second,
 	    j->get<2>()));
       }
-      ceph_assert(!need_attrs);
+//      ceph_assert(!need_attrs);
+    }
+    bool need_attrs = i->second.want_attrs;
+
+    for (auto j = i->second.need.begin();
+         j != i->second.need.end();
+	 ++j) {
+
+      if (need_attrs) {
+	messages[j->first].attrs_to_read.insert(i->first);
+	need_attrs = false;
+      }
+      if ((!i->second.partial_read) || (i->second.partial_read && (send_shards.find(j->first.shard) != send_shards.end()))) {
+	messages[j->first].subchunks[i->first] = j->second;
+	op.obj_to_source[i->first].insert(j->first);
+	op.source_to_obj[j->first].insert(i->first);
+      }
     }
   }
+  dout(20) << __func__ << " messages size: " << messages.size() << dendl;
 
   for (map<pg_shard_t, ECSubRead>::iterator i = messages.begin();
        i != messages.end();
@@ -1832,8 +1907,12 @@ ECUtil::HashInfoRef ECBackend::get_hash_info(
 void ECBackend::start_rmw(Op *op, PGTransactionUPtr &&t)
 {
   ceph_assert(op);
-
+  dout(20) << __func__ << ": " << *op << dendl;
+  bool cpr = can_partial_read(op->hoid);
+  op->ec_partial_read = cct->_conf->osd_ec_partial_read && cpr;
+  op->ec_partial_write = cct->_conf->osd_ec_partial_write && cpr;
   op->plan = ECTransaction::get_write_plan(
+    op->ec_partial_read && op->ec_partial_write,
     sinfo,
     std::move(t),
     [&](const hobject_t &i) {
@@ -1849,7 +1928,7 @@ void ECBackend::start_rmw(Op *op, PGTransactionUPtr &&t)
     },
     get_parent()->get_dpp());
 
-  dout(10) << __func__ << ": " << *op << dendl;
+  dout(20) << __func__ << ": " << *op << dendl;
 
   waiting_state.push_back(*op);
   check_ops();
@@ -1857,8 +1936,10 @@ void ECBackend::start_rmw(Op *op, PGTransactionUPtr &&t)
 
 bool ECBackend::try_state_to_reads()
 {
-  if (waiting_state.empty())
+  if (waiting_state.empty()) {
+    dout(20) << __func__ << ": waiting_state is empty" << dendl;
     return false;
+  }
 
   Op *op = &(waiting_state.front());
   if (op->requires_rmw() && pipeline_state.cache_invalid()) {
@@ -1891,7 +1972,7 @@ bool ECBackend::try_state_to_reads()
 	to_read_plan_iter == op->plan.to_read.end() ?
 	empty :
 	to_read_plan_iter->second;
-
+	   dout(20) << __func__ << ": hpair.first=" << hpair.first <<" hpair.second:"<<hpair.second<<" to_read_plan:"<<to_read_plan<< cache <<dendl;
       extent_set remote_read = cache.reserve_extents_for_rmw(
 	hpair.first,
 	op->pin,
@@ -1900,24 +1981,27 @@ bool ECBackend::try_state_to_reads()
 
       extent_set pending_read = to_read_plan;
       pending_read.subtract(remote_read);
-
+	dout(20) << __func__ << ": remote_read:"<< remote_read <<" pending_read after subtract:"<<pending_read<< cache << dendl;
       if (!remote_read.empty()) {
 	op->remote_read[hpair.first] = std::move(remote_read);
       }
+
       if (!pending_read.empty()) {
 	op->pending_read[hpair.first] = std::move(pending_read);
       }
     }
   } else {
     op->remote_read = op->plan.to_read;
+    dout(20) << __func__ << ": " << *op << dendl;
   }
 
-  dout(10) << __func__ << ": " << *op << dendl;
+  dout(20) << __func__ << ": " << *op << dendl;
 
   if (!op->remote_read.empty()) {
     ceph_assert(get_parent()->get_pool().allows_ecoverwrites());
     objects_read_async_no_cache(
       op->remote_read,
+     op->ec_partial_read,
       [this, op](map<hobject_t,pair<int, extent_map> > &&results) {
 	for (auto &&i: results) {
 	  op->remote_read_result.emplace(i.first, i.second.second);
@@ -1931,11 +2015,15 @@ bool ECBackend::try_state_to_reads()
 
 bool ECBackend::try_reads_to_commit()
 {
-  if (waiting_reads.empty())
+  if (waiting_reads.empty()) {
+    dout(20) << __func__ << ": waiting_reads is empty" << dendl;
     return false;
+  }
   Op *op = &(waiting_reads.front());
-  if (op->read_in_progress())
+  if (op->read_in_progress()) {
+    dout(20) << __func__ << ": op read in progress " << dendl;
     return false;
+  }
   waiting_reads.pop_front();
   waiting_commit.push_back(*op);
 
@@ -1948,11 +2036,13 @@ bool ECBackend::try_reads_to_commit()
 
   if (op->using_cache) {
     for (auto &&hpair: op->pending_read) {
+      dout(20) << __func__ << " : before cache.get_remaining_extents_for_rmw  " << cache << dendl;
       op->remote_read_result[hpair.first].insert(
 	cache.get_remaining_extents_for_rmw(
 	  hpair.first,
 	  op->pin,
 	  hpair.second));
+      	   dout(20) << __func__ << " : after cache.get_remaining_extents_for_rmw  " << cache << dendl;
     }
     op->pending_read.clear();
   } else {
@@ -1970,7 +2060,44 @@ bool ECBackend::try_reads_to_commit()
   op->trace.event("start ec write");
 
   map<hobject_t,extent_map> written;
+  bool have_append = false;
   if (op->plan.t) {
+
+  HiEcInfo ec_info(ec_impl->get_data_chunk_count(),ec_impl->get_chunk_count(),
+		   ec_impl->get_chunk_mapping(),sinfo.get_chunk_size(),
+		   sinfo.get_stripe_width());
+    set<int> want_to_read;
+    std::map<uint64_t,uint64_t> extents;
+    set<shard_id_t> write_sid;
+
+    for (auto &&ck : op->plan.to_read_chunk_align) {
+      ck.second.move_into(extents);
+
+      HiGetWriteToShards(extents, ec_info, want_to_read);
+
+      interval_set<uint64_t> tmp(extents);
+      ck.second = tmp;
+    }
+
+    for (auto &i : want_to_read) {
+      write_sid.insert(shard_id_t(i));
+    }
+
+    for (auto &&to_read: op->plan.to_read_chunk_align) {
+      map<pg_shard_t, vector<pair<int, int>>> shards;
+      int r = get_min_avail_to_read_shards(
+   to_read.first,
+   want_to_read,
+   false,
+   false,
+   &shards);
+
+   ceph_assert(r == 0);
+   for (const auto &shard: shards) {
+     op->write_to_shards.insert(shard.first);
+   }
+    }
+    
     ECTransaction::generate_transactions(
       op->plan,
       ec_impl,
@@ -1980,9 +2107,11 @@ bool ECBackend::try_reads_to_commit()
       op->log_entries,
       &written,
       &trans,
+      write_sid,
       &(op->temp_added),
       &(op->temp_cleared),
-      get_parent()->get_dpp());
+      get_parent()->get_dpp(),
+      have_append);
   }
 
   dout(20) << __func__ << ": " << cache << dendl;
@@ -2060,6 +2189,7 @@ bool ECBackend::try_reads_to_commit()
     if (*i == get_parent()->whoami_shard()) {
       should_write_local = true;
       local_write_op.claim(sop);
+      dout(20) << __func__ << ": write local sop: "<<sop<<dendl;
     } else {
       MOSDECSubOpWrite *r = new MOSDECSubOpWrite(sop);
       r->pgid = spg_t(get_parent()->primary_spg_t().pgid, i->shard);
@@ -2068,6 +2198,7 @@ bool ECBackend::try_reads_to_commit()
       r->trace = trace;
       get_parent()->send_message_osd_cluster(
 	i->osd, r, get_osdmap_epoch());
+      dout(20) << __func__ << ": send to remote osd sop: "<<sop<<dendl;
     }
   }
   if (should_write_local) {
@@ -2089,11 +2220,15 @@ bool ECBackend::try_reads_to_commit()
 
 bool ECBackend::try_finish_rmw()
 {
-  if (waiting_commit.empty())
+  if (waiting_commit.empty()) {
+    dout(20) << __func__ << ":waiting_commit is empty" << dendl;
     return false;
+  }
   Op *op = &(waiting_commit.front());
-  if (op->write_in_progress())
+  if (op->write_in_progress()) {
+    dout(20) << __func__ << ":op write in progress" << dendl;
     return false;
+  }
   waiting_commit.pop_front();
 
   dout(10) << __func__ << ": " << *op << dendl;
@@ -2117,11 +2252,14 @@ bool ECBackend::try_finish_rmw()
       nop->tid = tid;
       nop->reqid = op->reqid;
       waiting_reads.push_back(*nop);
+      dout(20) << __func__ << ": waiting_reads push nop" << *nop <<dendl;
     }
   }
 
   if (op->using_cache) {
+    dout(20) << __func__ << ": before cache release_write_pin "<< cache << dendl;
     cache.release_write_pin(op->pin);
+    dout(20) << __func__ << ": after cache release_write_pin" << cache << dendl;
   }
   tid_to_op_map.erase(op->tid);
 
@@ -2137,9 +2275,11 @@ bool ECBackend::try_finish_rmw()
 
 void ECBackend::check_ops()
 {
+  dout(20) << __func__ << ": start" <<dendl;
   while (try_state_to_reads() ||
 	 try_reads_to_commit() ||
 	 try_finish_rmw());
+  dout(20) << __func__ << ": finish" <<dendl;
 }
 
 int ECBackend::objects_read_sync(
@@ -2159,26 +2299,36 @@ void ECBackend::objects_read_async(
   Context *on_complete,
   bool fast_read)
 {
-  map<hobject_t,std::list<boost::tuple<uint64_t, uint64_t, uint32_t> > >
+  map<hobject_t,std::pair<std::list<boost::tuple<uint64_t, uint64_t, uint32_t> >, bool> >
     reads;
 
   uint32_t flags = 0;
+  bool object_can_partial_read = false;
+  if (cct->_conf->osd_ec_partial_read) {
+    object_can_partial_read = can_partial_read(hoid);
+  }
+  dout(20) << __func__ << "hobject_t:" << hoid << "partial read is " << object_can_partial_read << dendl;
   extent_set es;
   for (list<pair<boost::tuple<uint64_t, uint64_t, uint32_t>,
 	 pair<bufferlist*, Context*> > >::const_iterator i =
 	 to_read.begin();
        i != to_read.end();
        ++i) {
-    pair<uint64_t, uint64_t> tmp =
-      sinfo.offset_len_to_stripe_bounds(
+    pair<uint64_t, uint64_t> tmp;
+    if (object_can_partial_read) {
+      tmp=sinfo.offset_len_to_chunk_bounds(
 	make_pair(i->first.get<0>(), i->first.get<1>()));
-
+    } else {
+      tmp=sinfo.offset_len_to_stripe_bounds(
+	make_pair(i->first.get<0>(), i->first.get<1>()));
+    }
     es.union_insert(tmp.first, tmp.second);
     flags |= i->first.get<2>();
   }
 
   if (!es.empty()) {
-    auto &offsets = reads[hoid];
+    auto &offsets = reads[hoid].first;
+    reads[hoid].second = object_can_partial_read;
     for (auto j = es.begin();
 	 j != es.end();
 	 ++j) {
@@ -2277,33 +2427,81 @@ struct CallClientContexts :
   ECBackend *ec;
   ECBackend::ClientAsyncReadStatus *status;
   list<boost::tuple<uint64_t, uint64_t, uint32_t> > to_read;
+  bool partial_read;
   CallClientContexts(
     hobject_t hoid,
     ECBackend *ec,
     ECBackend::ClientAsyncReadStatus *status,
-    const list<boost::tuple<uint64_t, uint64_t, uint32_t> > &to_read)
-    : hoid(hoid), ec(ec), status(status), to_read(to_read) {}
+    const list<boost::tuple<uint64_t, uint64_t, uint32_t> > &to_read, bool partial_read = false)
+    : hoid(hoid), ec(ec), status(status), to_read(to_read), partial_read(partial_read) {}
+
+  void reconstruct_shard(unsigned int start, unsigned int count , uint64_t len,
+    map<int, bufferlist> &to_decode, bufferlist *out) {
+
+    auto dpp=ec->get_parent()->get_dpp();
+    ldpp_dout(dpp,20) << "reconstruct_shard start: " << start << "count:" << count << "len:" << len << dendl;
+
+    vector<int> chunk_idx;
+    HiEcInfo ec_info(ec->ec_impl->get_data_chunk_count(), ec->ec_impl->get_chunk_count(),
+		     ec->ec_impl->get_chunk_mapping(), ec->sinfo.get_chunk_size(),
+		     ec->sinfo.get_stripe_width());
+    HiGetReconstructShards(start, count, len, ec_info, chunk_idx);
+
+    for(auto idx : chunk_idx) {
+      bufferlist bl;
+      if (to_decode[idx].length() == 0) {
+	continue;
+      }
+      to_decode[idx].splice(0, ec->sinfo.get_chunk_size(), &bl);
+      out->claim_append(bl);
+    }
+  }
+
+  void reconstruct(pair<uint64_t, uint64_t> in, map<int, bufferlist> &to_decode, bufferlist *out) {
+
+    auto dpp=ec->get_parent()->get_dpp();
+    ldpp_dout(dpp, 20) <<" in: " << in << dendl;
+
+    HiEcInfo ec_info(ec->ec_impl->get_data_chunk_count(), ec->ec_impl->get_chunk_count(),
+		     ec->ec_impl->get_chunk_mapping(), ec->sinfo.get_chunk_size(),
+		     ec->sinfo.get_stripe_width());
+    vector<boost::tuple<unsigned int, unsigned int, unsigned int>> chunk_info;
+    HiReconstructPrepare(ec_info, in, chunk_info);
+
+    for (auto info : chunk_info)
+    	reconstruct_shard(info.get<0>(), info.get<1>(), info.get<2>(), to_decode, out);
+  }
+
   void finish(pair<RecoveryMessages *, ECBackend::read_result_t &> &in) override {
     ECBackend::read_result_t &res = in.second;
     extent_map result;
+    auto dpp=ec->get_parent()->get_dpp();
     if (res.r != 0)
       goto out;
     ceph_assert(res.returned.size() == to_read.size());
     ceph_assert(res.errors.empty());
+    ldpp_dout(dpp, 20) << "read_result_t: " << res << dendl;
     for (auto &&read: to_read) {
-      pair<uint64_t, uint64_t> adjusted =
-	ec->sinfo.offset_len_to_stripe_bounds(
+      bufferlist bl;
+      pair<uint64_t, uint64_t> adjusted;
+      if (!partial_read) {
+       adjusted = ec->sinfo.offset_len_to_stripe_bounds(
+         make_pair(read.get<0>(), read.get<1>()));
+      } else {
+       adjusted = ec->sinfo.offset_len_to_chunk_bounds(
 	  make_pair(read.get<0>(), read.get<1>()));
+      }
       ceph_assert(res.returned.front().get<0>() == adjusted.first &&
 	     res.returned.front().get<1>() == adjusted.second);
       map<int, bufferlist> to_decode;
-      bufferlist bl;
       for (map<pg_shard_t, bufferlist>::iterator j =
 	     res.returned.front().get<2>().begin();
 	   j != res.returned.front().get<2>().end();
 	   ++j) {
 	to_decode[j->first.shard].claim(j->second);
       }
+      ldpp_dout(dpp, 20) << "reconstruct: " << adjusted << " to_decode: " << to_decode << dendl;
+      if (!partial_read) {
       int r = ECUtil::decode(
 	ec->sinfo,
 	ec->ec_impl,
@@ -2313,9 +2511,12 @@ struct CallClientContexts :
         res.r = r;
         goto out;
       }
+     } else {
+      reconstruct(adjusted, to_decode, &bl);
+     }
       bufferlist trimmed;
       trimmed.substr_of(
-	bl,
+   bl,
 	read.get<0>() - adjusted.first,
 	std::min(read.get<1>(),
 	    bl.length() - (read.get<0>() - adjusted.first)));
@@ -2331,7 +2532,7 @@ out:
 
 void ECBackend::objects_read_and_reconstruct(
   const map<hobject_t,
-    std::list<boost::tuple<uint64_t, uint64_t, uint32_t> >
+    std::pair<std::list<boost::tuple<uint64_t, uint64_t, uint32_t> >, bool>
   > &reads,
   bool fast_read,
   GenContextURef<map<hobject_t,pair<int, extent_map> > &&> &&func)
@@ -2357,20 +2558,21 @@ void ECBackend::objects_read_and_reconstruct(
       fast_read,
       &shards);
     ceph_assert(r == 0);
-
+    dout(20) << __func__ << " : want_to_read=" << want_to_read << "    shards=" <<shards<< dendl;
     CallClientContexts *c = new CallClientContexts(
       to_read.first,
       this,
       &(in_progress_client_reads.back()),
-      to_read.second);
+      to_read.second.first,to_read.second.second);
     for_read_op.insert(
       make_pair(
 	to_read.first,
 	read_request_t(
-	  to_read.second,
+	  to_read.second.first,
 	  shards,
 	  false,
-	  c)));
+	  c,
+	  to_read.second.second)));
     obj_want_to_read.insert(make_pair(to_read.first, want_to_read));
   }
 
diff --git a/src/osd/ECBackend.h b/src/osd/ECBackend.h
index e003a08..791d445 100644
--- a/src/osd/ECBackend.h
+++ b/src/osd/ECBackend.h
@@ -18,6 +18,8 @@
 #include <boost/intrusive/set.hpp>
 #include <boost/intrusive/list.hpp>
 
+#include "include/on_exit.h"
+
 #include "OSD.h"
 #include "PGBackend.h"
 #include "erasure-code/ErasureCodeInterface.h"
@@ -137,7 +139,7 @@ public:
    * check_recovery_sources.
    */
   void objects_read_and_reconstruct(
-    const map<hobject_t, std::list<boost::tuple<uint64_t, uint64_t, uint32_t> >
+    const std::map<hobject_t, std::pair<std::list<boost::tuple<uint64_t, uint64_t, uint32_t>>, bool >
     > &reads,
     bool fast_read,
     GenContextURef<map<hobject_t,pair<int, extent_map> > &&> &&func);
@@ -167,6 +169,26 @@ public:
       func.release()->complete(std::move(results));
     }
   };
+  bool can_partial_read(const hobject_t &hoid)
+  {
+    if (get_parent()->get_pool().fast_read) {
+      return false;
+    }
+    set<int> want_to_read;
+    get_want_to_read_shards(&want_to_read);
+
+    set<int> have;
+    map<shard_id_t, pg_shard_t> shards;
+    set<pg_shard_t> error_shards;
+    get_all_avail_shards(hoid, error_shards, have, shards, false);
+
+    if (includes(have.begin(), have.end(), want_to_read.begin(), want_to_read.end())) {
+      return true;
+    }
+    return false;
+  }
+
+  void get_off_len_shards( uint64_t off, uint64_t len, set<int>& out);
   list<ClientAsyncReadStatus> in_progress_client_reads;
   void objects_read_async(
     const hobject_t &hoid,
@@ -178,21 +200,33 @@ public:
   template <typename Func>
   void objects_read_async_no_cache(
     const map<hobject_t,extent_set> &to_read,
+    bool partial_read,
     Func &&on_complete) {
-    map<hobject_t,std::list<boost::tuple<uint64_t, uint64_t, uint32_t> > > _to_read;
+    std::map<hobject_t,std::pair<std::list<boost::tuple<uint64_t, uint64_t, uint32_t> >,bool > > _to_read;
     for (auto &&hpair: to_read) {
       auto &l = _to_read[hpair.first];
+      l.second = partial_read;
       for (auto extent: hpair.second) {
-	l.emplace_back(extent.first, extent.second, 0);
+  uint64_t off = extent.first;
+  uint64_t len = extent.second;
+  if (l.second) {
+    pair<uint64_t,uint64_t> tmp = sinfo.offset_len_to_chunk_bounds(
+    make_pair(extent.first, extent.second));
+    off = tmp.first;
+    len = tmp.second;
+  }
+ 	l.first.emplace_back(off, len, 0); 
       }
     }
-    objects_read_and_reconstruct(
-      _to_read,
-      false,
-      make_gen_lambda_context<
-      map<hobject_t,pair<int, extent_map> > &&, Func>(
-	  std::forward<Func>(on_complete)));
+
+  objects_read_and_reconstruct(
+  _to_read,
+  false,
+  make_gen_lambda_context<
+  map<hobject_t,pair<int, extent_map> > &&, Func>(
+  std::forward<Func>(on_complete)));
   }
+
   void kick_reads() {
     while (in_progress_client_reads.size() &&
 	   in_progress_client_reads.front().is_complete()) {
@@ -355,13 +389,15 @@ public:
     const map<pg_shard_t, vector<pair<int, int>>> need;
     const bool want_attrs;
     GenContext<pair<RecoveryMessages *, read_result_t& > &> *cb;
+    const bool partial_read;
     read_request_t(
       const list<boost::tuple<uint64_t, uint64_t, uint32_t> > &to_read,
       const map<pg_shard_t, vector<pair<int, int>>> &need,
       bool want_attrs,
-      GenContext<pair<RecoveryMessages *, read_result_t& > &> *cb)
+      GenContext<pair<RecoveryMessages *, read_result_t& > &> *cb,
+      bool partial_read = false)
       : to_read(to_read), need(need), want_attrs(want_attrs),
-	cb(cb) {}
+    cb(cb), partial_read(partial_read) {}
   };
   friend ostream &operator<<(ostream &lhs, const read_request_t &rhs);
 
@@ -485,6 +521,9 @@ public:
     map<hobject_t,extent_set> pending_read; // subset already being read
     map<hobject_t,extent_set> remote_read;  // subset we must read
     map<hobject_t,extent_map> remote_read_result;
+    bool ec_partial_read;
+    bool ec_partial_write;
+    
     bool read_in_progress() const {
       return !remote_read.empty() && remote_read_result.empty();
     }
@@ -495,6 +534,9 @@ public:
     // read on a remote shard before it has applied a previous write.  We can
     // remove this after nautilus.
     set<pg_shard_t> pending_apply;
+
+    set<pg_shard_t> write_to_shards;
+
     bool write_in_progress() const {
       return !pending_commit.empty() || !pending_apply.empty();
     }
@@ -572,6 +614,7 @@ public:
 
   ErasureCodeInterfaceRef ec_impl;
 
+  OnExitManager exit_callbacks;
 
   /**
    * ECRecPred
@@ -602,6 +645,10 @@ public:
     return new ECRecPred(ec_impl);
   }
 
+  int get_ec_chunk_count() const  {
+   return ec_impl->get_chunk_count();
+  }
+  
   int get_ec_data_chunk_count() const override {
     return ec_impl->get_data_chunk_count();
   }
diff --git a/src/osd/ECTransaction.cc b/src/osd/ECTransaction.cc
index ee791d6..3e68845 100644
--- a/src/osd/ECTransaction.cc
+++ b/src/osd/ECTransaction.cc
@@ -34,6 +34,8 @@ void encode_and_write(
   ECUtil::HashInfoRef hinfo,
   extent_map &written,
   map<shard_id_t, ObjectStore::Transaction> *transactions,
+  bool overwrite,
+  set<shard_id_t> &write_sid,
   DoutPrefixProvider *dpp) {
   const uint64_t before_size = hinfo->get_total_logical_size(sinfo);
   ceph_assert(sinfo.logical_offset_is_stripe_aligned(offset));
@@ -60,7 +62,15 @@ void encode_and_write(
   }
 
   for (auto &&i : *transactions) {
-    ceph_assert(buffers.count(i.first));
+   ceph_assert(buffers.count(i.first));
+
+
+   if(overwrite && (write_sid.find(i.first) == write_sid.end())) {
+     ldpp_dout(dpp,20) << __func__ << ": transactions is continue write_sid=" << write_sid << "  i.first=" << i.first << dendl;
+     continue;
+   }
+
+   
     bufferlist &enc_bl = buffers[i.first];
     if (offset >= before_size) {
       i.second.set_alloc_hint(
@@ -74,13 +84,14 @@ void encode_and_write(
       coll_t(spg_t(pgid, i.first)),
       ghobject_t(oid, ghobject_t::NO_GEN, i.first),
       sinfo.logical_to_prev_chunk_offset(
-	offset),
+       offset),
       enc_bl.length(),
       enc_bl,
       flags);
   }
 }
 
+
 bool ECTransaction::requires_overwrite(
   uint64_t prev_size,
   const PGTransaction::ObjectOperation &op) {
@@ -103,9 +114,11 @@ void ECTransaction::generate_transactions(
   vector<pg_log_entry_t> &entries,
   map<hobject_t,extent_map> *written_map,
   map<shard_id_t, ObjectStore::Transaction> *transactions,
+  set<shard_id_t> &write_sid,
   set<hobject_t> *temp_added,
   set<hobject_t> *temp_removed,
-  DoutPrefixProvider *dpp)
+  DoutPrefixProvider *dpp,
+  bool &have_append)
 {
   ceph_assert(written_map);
   ceph_assert(transactions);
@@ -506,14 +519,15 @@ void ECTransaction::generate_transactions(
 	  end += tail;
 	  len += tail;
 	}
-
+	ldpp_dout(dpp, 20) << __func__ << ": to_write="<<to_write<<" off="<<off<<" len="<<len<<" bl="<<bl<< dendl;
 	to_write.insert(off, len, bl);
+	ldpp_dout(dpp, 20) << __func__ << ": after insert to_write="<<to_write<<" bl="<<bl<< dendl;
 	if (end > new_size)
 	  new_size = end;
       }
 
       if (op.truncate &&
-	  op.truncate->second > new_size) {
+        op.truncate->second > new_size) {
 	ceph_assert(op.truncate->second > append_after);
 	uint64_t truncate_to =
 	  sinfo.logical_to_next_stripe_offset(
@@ -537,8 +551,8 @@ void ECTransaction::generate_transactions(
       }
       auto to_overwrite = to_write.intersect(0, append_after);
       ldpp_dout(dpp, 20) << __func__ << ": to_overwrite: "
-			 << to_overwrite
-			 << dendl;
+        << to_overwrite
+        << dendl;
       for (auto &&extent: to_overwrite) {
 	ceph_assert(extent.get_off() + extent.get_len() <= append_after);
 	ceph_assert(sinfo.logical_offset_is_stripe_aligned(extent.get_off()));
@@ -548,7 +562,7 @@ void ECTransaction::generate_transactions(
 	    extent.get_off());
 	  uint64_t restore_len = sinfo.aligned_logical_offset_to_chunk_offset(
 	    extent.get_len());
-	  ldpp_dout(dpp, 20) << __func__ << ": overwriting "
+	  ldpp_dout(dpp, 20) << __func__ << ": overwriting section "
 			     << restore_from << "~" << restore_len
 			     << dendl;
 	  if (rollback_extents.empty()) {
@@ -581,6 +595,8 @@ void ECTransaction::generate_transactions(
 	  hinfo,
 	  written,
 	  transactions,
+	  true,
+	  write_sid,
 	  dpp);
       }
 
@@ -588,12 +604,12 @@ void ECTransaction::generate_transactions(
 	append_after,
 	std::numeric_limits<uint64_t>::max() - append_after);
       ldpp_dout(dpp, 20) << __func__ << ": to_append: "
-			 << to_append
-			 << dendl;
+	<< to_append
+	<< dendl;
       for (auto &&extent: to_append) {
 	ceph_assert(sinfo.logical_offset_is_stripe_aligned(extent.get_off()));
 	ceph_assert(sinfo.logical_offset_is_stripe_aligned(extent.get_len()));
-	ldpp_dout(dpp, 20) << __func__ << ": appending "
+	ldpp_dout(dpp, 20) << __func__ << ": appending section "
 			   << extent.get_off() << "~" << extent.get_len()
 			   << dendl;
 	encode_and_write(
@@ -608,13 +624,15 @@ void ECTransaction::generate_transactions(
 	  hinfo,
 	  written,
 	  transactions,
+	  false,
+	  write_sid,
 	  dpp);
       }
 
       ldpp_dout(dpp, 20) << __func__ << ": " << oid
-			 << " resetting hinfo to logical size "
-			 << new_size
-			 << dendl;
+	<< " resetting hinfo to logical size "
+	<< new_size
+	<< dendl;
       if (!rollback_extents.empty() && entry) {
 	if (entry) {
 	  ldpp_dout(dpp, 20) << __func__ << ": " << oid
@@ -635,6 +653,7 @@ void ECTransaction::generate_transactions(
 			   << append_after
 			   << dendl;
 	entry->mod_desc.append(append_after);
+	have_append = true;
       }
 
       if (!op.is_delete()) {
@@ -650,3 +669,7 @@ void ECTransaction::generate_transactions(
       }
     });
 }
+
+
+
+
diff --git a/src/osd/ECTransaction.h b/src/osd/ECTransaction.h
index ae0faf5..53e82af 100644
--- a/src/osd/ECTransaction.h
+++ b/src/osd/ECTransaction.h
@@ -21,13 +21,14 @@
 #include "erasure-code/ErasureCodeInterface.h"
 #include "PGTransaction.h"
 #include "ExtentCache.h"
-
+#include "hi_coreutil.h"
 namespace ECTransaction {
   struct WritePlan {
     PGTransactionUPtr t;
     bool invalidates_cache = false; // Yes, both are possible
     map<hobject_t,extent_set> to_read;
     map<hobject_t,extent_set> will_write; // superset of to_read
+    map<hobject_t,extent_set> to_read_chunk_align;
 
     map<hobject_t,ECUtil::HashInfoRef> hash_infos;
   };
@@ -38,6 +39,7 @@ namespace ECTransaction {
 
   template <typename F>
   WritePlan get_write_plan(
+    bool partial_write,
     const ECUtil::stripe_info_t &sinfo,
     PGTransactionUPtr &&t,
     F &&get_hinfo,
@@ -50,6 +52,12 @@ namespace ECTransaction {
 
 	uint64_t projected_size =
 	  hinfo->get_projected_total_logical_size(sinfo);
+	uint64_t chunk_size = sinfo.get_chunk_size();
+	ceph_assert(chunk_size);
+	ldpp_dout(dpp, 20) << __func__ << ": projected_size=" << projected_size
+	  << "  projected_total_chunk_size=" << hinfo->get_projected_total_chunk_size()
+	  << "  stripe_width=" << sinfo.get_stripe_width() << "  chunk_size=" << chunk_size
+	  << "  partial_write=" << partial_write << dendl;
 
 	if (i.second.deletes_first()) {
 	  ldpp_dout(dpp, 20) << __func__ << ": delete, setting projected size"
@@ -63,6 +71,7 @@ namespace ECTransaction {
 
 	  ECUtil::HashInfoRef shinfo = get_hinfo(source);
 	  projected_size = shinfo->get_projected_total_logical_size(sinfo);
+	  ldpp_dout(dpp, 20) << __func__ << ": second.has_source projected_size=" << projected_size<<dendl;
 	  plan.hash_infos[source] = shinfo;
 	}
 
@@ -83,6 +92,7 @@ namespace ECTransaction {
 	  }
 	  projected_size = sinfo.logical_to_next_stripe_offset(
 	    i.second.truncate->first);
+	  ldpp_dout(dpp, 20) << __func__ << ": i.second.truncate projected_size=" << projected_size<<dendl;
 	}
 
 	extent_set raw_write_set;
@@ -94,6 +104,7 @@ namespace ECTransaction {
 	      "CloneRange is not allowed, do_op should have returned ENOTSUPP");
 	  }
 	  raw_write_set.insert(extent.get_off(), extent.get_len());
+	  ldpp_dout(dpp, 20) << __func__ << ": extent.get_off()=" << extent.get_off() << " extent.get_len()=" << extent.get_len() << dendl;
 	}
 
 	auto orig_size = projected_size;
@@ -104,6 +115,8 @@ namespace ECTransaction {
 	    sinfo.logical_to_prev_stripe_offset(extent.get_start());
 	  uint64_t head_finish =
 	    sinfo.logical_to_next_stripe_offset(extent.get_start());
+	  ldpp_dout(dpp, 20) << __func__ << ": head_start=" << head_start << " head_finish=" << head_finish
+	   << "  projected_size=" << projected_size << " orig_size=" << orig_size << dendl;
 	  if (head_start > projected_size) {
 	    head_start = projected_size;
 	  }
@@ -124,6 +137,8 @@ namespace ECTransaction {
 	  uint64_t tail_finish =
 	    sinfo.logical_to_next_stripe_offset(
 	      extent.get_start() + extent.get_len());
+	  ldpp_dout(dpp, 20) << __func__ <<"tail_start=" <<tail_start<<"tail_finish="<<tail_finish<<
+	    "   orig_size="<<orig_size<<dendl;
 	  if (tail_start != tail_finish &&
 	      (head_start == head_finish || tail_start != head_start) &&
 	      tail_start < orig_size) {
@@ -143,11 +158,22 @@ namespace ECTransaction {
 	      );
 	    will_write.union_insert(
 	      head_start, tail_finish - head_start);
+	    ldpp_dout(dpp, 20) << __func__ << ": head_start != tail_finish " << head_start << "!=" <<tail_finish<< dendl;
 	    if (tail_finish > projected_size)
 	      projected_size = tail_finish;
 	  } else {
 	    ceph_assert(tail_finish <= projected_size);
 	  }
+	    uint64_t hi_head_start = 0, hi_head_len = 0;
+
+	    if(
+	        partial_write && HiSetWriteSection(extent.get_start(), extent.get_len(), chunk_size, hi_head_start, hi_head_len)
+	    ) {
+	      plan.to_read_chunk_align[i.first].union_insert(hi_head_start, hi_head_len);
+	    } else {
+	      plan.to_read_chunk_align[i.first] = will_write;
+	      partial_write = false;
+	    }
 	}
 
 	if (i.second.truncate &&
@@ -161,7 +187,22 @@ namespace ECTransaction {
 				  truncating_to - projected_size);
 	  projected_size = truncating_to;
 	}
-
+	 if (partial_write) {
+	     if(plan.to_read.count(i.first) != 0) {
+		 map<uint64_t, uint64_t> write_set;
+		 raw_write_set.move_into(write_set);
+		 map<uint64_t, uint64_t> to_read;
+		 plan.to_read[i.first].move_into(to_read);
+		 ldpp_dout(dpp, 20) << __func__ << ": partial_write=" << partial_write << " write_set=" << write_set
+		     << " to_read=" << to_read << dendl;
+                 if(HiRebuildToread(write_set, chunk_size, to_read)) {
+	             ldpp_dout(dpp, 20) << __func__ << ": to_read=" << to_read << dendl;
+		     plan.to_read[i.first].clear();
+		     plan.to_read[i.first].insert(extent_set(to_read));
+		 }
+	     }
+	 }
+	 
 	ldpp_dout(dpp, 20) << __func__ << ": " << i.first
 			   << " projected size "
 			   << projected_size
@@ -191,9 +232,13 @@ namespace ECTransaction {
     vector<pg_log_entry_t> &entries,
     map<hobject_t,extent_map> *written,
     map<shard_id_t, ObjectStore::Transaction> *transactions,
+    set<shard_id_t> &read_sid,
     set<hobject_t> *temp_added,
     set<hobject_t> *temp_removed,
-    DoutPrefixProvider *dpp);
+    DoutPrefixProvider *dpp,
+    bool &have_append);
+
 };
 
+
 #endif
diff --git a/src/osd/ECUtil.h b/src/osd/ECUtil.h
index 8e980e2..65b6770 100644
--- a/src/osd/ECUtil.h
+++ b/src/osd/ECUtil.h
@@ -22,6 +22,9 @@
 #include "include/encoding.h"
 #include "common/Formatter.h"
 
+namespace {
+const uint64_t MAX_CHUNK_END = (1ULL << 40);
+}
 namespace ECUtil {
 
 class stripe_info_t {
@@ -36,6 +39,7 @@ public:
   bool logical_offset_is_stripe_aligned(uint64_t logical) const {
     return (logical % stripe_width) == 0;
   }
+
   uint64_t get_stripe_width() const {
     return stripe_width;
   }
@@ -48,6 +52,7 @@ public:
   uint64_t logical_to_next_chunk_offset(uint64_t offset) const {
     return ((offset + stripe_width - 1)/ stripe_width) * chunk_size;
   }
+
   uint64_t logical_to_prev_stripe_offset(uint64_t offset) const {
     return offset - (offset % stripe_width);
   }
@@ -77,6 +82,32 @@ public:
       (in.first - off) + in.second);
     return std::make_pair(off, len);
   }
+  uint64_t logical_to_prev_chunk(uint64_t offset) const {
+    return offset - (offset % chunk_size);
+  }
+
+  uint64_t logical_to_next_chunk(uint64_t offset) const {
+   if (offset > MAX_CHUNK_END || chunk_size > MAX_CHUNK_END) {
+	   return MAX_CHUNK_END;
+   }
+  uint64_t ret = offset % MAX_CHUNK_END;
+  uint64_t redundant = offset % chunk_size;
+  if (redundant != 0) {
+      if (offset - redundant + chunk_size < MAX_CHUNK_END) {
+	  ret = offset - redundant + chunk_size;
+      } else {
+	  ret = MAX_CHUNK_END;
+      }
+  }
+  return ret;
+}
+std::pair<uint64_t, uint64_t> offset_len_to_chunk_bounds(
+  std::pair<uint64_t, uint64_t> in) const {
+  uint64_t off = logical_to_prev_chunk(in.first);
+  uint64_t len = logical_to_next_chunk(
+    (in.first - off) + in.second);
+  return std::make_pair(off, len);
+}
 };
 
 int decode(
diff --git a/src/osd/OSD.cc b/src/osd/OSD.cc
index 8d9ab9c..4f7df42 100644
--- a/src/osd/OSD.cc
+++ b/src/osd/OSD.cc
@@ -27,6 +27,8 @@
 #include <boost/scoped_ptr.hpp>
 #include <boost/range/adaptor/reversed.hpp>
 
+#include <hi_coreutil.h>
+
 #ifdef HAVE_SYS_PARAM_H
 #include <sys/param.h>
 #endif
@@ -3219,6 +3221,8 @@ int OSD::init()
 
   clear_temp_objects();
 
+  HiInit("/etc/ceph/ceph.conf", cct->_conf->name.get_id());
+
   // initialize osdmap references in sharded wq
   for (auto& shard : shards) {
     std::lock_guard l(shard->osdmap_lock);
@@ -11499,8 +11503,8 @@ int heap(CephContext& cct, const cmdmap_t& cmdmap, Formatter& f,
   
   return 0;
 }
- 
-}} // namespace ceph::osd_cmds
+}
+} // namespace ceph::osd_cmds
 
 
 std::ostream& operator<<(std::ostream& out, const io_queue& q) {
diff --git a/src/test/osd/test_ec_transaction.cc b/src/test/osd/test_ec_transaction.cc
index 9866966..a48a79b 100644
--- a/src/test/osd/test_ec_transaction.cc
+++ b/src/test/osd/test_ec_transaction.cc
@@ -39,6 +39,7 @@ TEST(ectransaction, two_writes_separated)
 
   ECUtil::stripe_info_t sinfo(2, 8192);
   auto plan = ECTransaction::get_write_plan(
+    dpp.get_cct()->_conf->osd_ec_partial_write && dpp.get_cct()->_conf->osd_ec_partial_read,
     sinfo,
     std::move(t),
     [&](const hobject_t &i) {
@@ -68,6 +69,7 @@ TEST(ectransaction, two_writes_nearby)
   t->write(h, 569856, b.length(), b, 0);
 
   auto plan = ECTransaction::get_write_plan(
+    dpp.get_cct()->_conf->osd_ec_partial_write && dpp.get_cct()->_conf->osd_ec_partial_read,
     sinfo,
     std::move(t),
     [&](const hobject_t &i) {
@@ -109,6 +111,7 @@ TEST(ectransaction, many_writes)
   t->write(h, 2813952, b.length(), b, 0);
 
   auto plan = ECTransaction::get_write_plan(
+    dpp.get_cct()->_conf->osd_ec_partial_write && dpp.get_cct()->_conf->osd_ec_partial_read,
     sinfo,
     std::move(t),
     [&](const hobject_t &i) {
